This Python sample code demonstrates how to use open-source large language models like Mixtral 8x7B and GTE-Large embedding models with Pinecone serverless vector db to give large language models long-term conversational memory based on the following novel retrieval augmented generation architecture.

![image](https://github.com/Packratt/ConvoRAG/assets/61139261/8686d88f-32ec-458f-a102-5886e9460828)

